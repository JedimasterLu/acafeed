{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2687f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Checkpoint dir: /Users/jylu/Projects/acafeed/model/checkpoint_model1\n"
     ]
    }
   ],
   "source": [
    "# ÂØºÂÖ•Â∫ì‰∏éÂü∫Á°ÄÈÖçÁΩÆ\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "# ËÆæÂ§á‰∏éÈöèÊú∫ÁßçÂ≠ê\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# checkpoint ÁõÆÂΩï\n",
    "CHECKPOINT_DIR = Path(\"model/checkpoint_model1\")\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LAST_CKPT = CHECKPOINT_DIR / \"model1_last.pt\"\n",
    "BEST_CKPT = CHECKPOINT_DIR / \"model1_best.pt\"\n",
    "\n",
    "print(\"Checkpoint dir:\", CHECKPOINT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f07694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2734420, Testing samples: 143917\n",
      "Number of labels: 174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1514aaf7b0b445db5cef6c3e11fc6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0329af14f1a24b9bb55c720ae1b5a287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËÆ≠ÁªÉÈõÜ: 50000 Ê†∑Êú¨, ÊµãËØïÈõÜ: 100 Ê†∑Êú¨\n",
      "Model initialized: DistilBertForSequenceClassification\n",
      "Num labels: 174\n",
      "Problem type: multi_label_classification\n",
      "Model initialized: DistilBertForSequenceClassification\n",
      "Num labels: 174\n",
      "Problem type: multi_label_classification\n"
     ]
    }
   ],
   "source": [
    "# ÂÆö‰πâÊï∞ÊçÆÈõÜ‰∏éÂ§öÊ†áÁ≠æÊ®°ÂûãÔºàModel1Ôºâ\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# ‰∏∫‰∫ÜÂ§çÁî®ÂéüÂßãÊï∞ÊçÆÔºåËøôÈáå‰ªéÁé∞ÊúâÁöÑ arxiv JSON ÊûÑÂª∫‰∏é model.ipynb ‰∏ÄËá¥ÁöÑÊï∞ÊçÆÊµÅÁ®ã\n",
    "file_path = os.path.expanduser(\"~/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/259/arxiv-metadata-oai-snapshot.json\")\n",
    "\n",
    "chunks = pd.read_json(file_path, lines=True, chunksize=100000)\n",
    "dfs = []\n",
    "for chunk in chunks:\n",
    "    dfs.append(chunk[[\"title\", \"categories\"]])\n",
    "\n",
    "df_small = pd.concat(dfs, ignore_index=True)\n",
    "raw_df = df_small.rename(columns={\"categories\": \"Category\", \"title\": \"Title\"})\n",
    "raw_df[\"Category\"] = raw_df[\"Category\"].str.split(\" \")\n",
    "raw_df[\"Title\"] = raw_df[\"Title\"].str.strip()\n",
    "\n",
    "# ÁªüËÆ°Á±ªÂà´Âπ∂ËøáÊª§‰ΩéÈ¢ëÁ±ªÂà´\n",
    "all_categories = [c for sub in raw_df[\"Category\"] for c in sub]\n",
    "category_counts = pd.Series(all_categories).value_counts()\n",
    "filtered_categories = category_counts[category_counts >= 20].index.tolist()\n",
    "\n",
    "category_to_id = {cat: idx for idx, cat in enumerate(filtered_categories)}\n",
    "label2id = category_to_id\n",
    "id2label = {v: k for k, v in category_to_id.items()}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def encode_labels(cats):\n",
    "    labels = np.zeros(len(category_to_id), dtype=float)\n",
    "    for cat in cats:\n",
    "        if cat in category_to_id:\n",
    "            labels[category_to_id[cat]] = 1.0\n",
    "    return labels\n",
    "\n",
    "filtered_df = raw_df[raw_df[\"Category\"].apply(lambda cats: any(cat in filtered_categories for cat in cats))].reset_index(drop=True)\n",
    "filtered_df[\"label\"] = filtered_df[\"Category\"].apply(encode_labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(filtered_df, test_size=0.05, random_state=SEED)\n",
    "print(f\"Training samples: {len(train_df)}, Testing samples: {len(test_df)}\")\n",
    "print(f\"Number of labels: {len(category_to_id)}\")\n",
    "\n",
    "# ËΩ¨‰∏∫ HF Dataset\n",
    "# ÈôêÂà∂‰∏™Êï∞\n",
    "TRAINNUM = 50000\n",
    "TESTNUM = 100\n",
    "# Randomly select a subset for quicker testing\n",
    "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True).sample(TRAINNUM, random_state=SEED)).shuffle(seed=SEED)\n",
    "test_ds = Dataset.from_pandas(test_df.reset_index(drop=True).sample(TESTNUM, random_state=SEED)).shuffle(seed=SEED)\n",
    "\n",
    "max_length = 64\n",
    "tokenizer_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized = tokenizer(batch[\"Title\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    tokenized[\"labels\"] = batch[\"label\"]\n",
    "    return tokenized\n",
    "\n",
    "train_tokenized = train_ds.map(tokenize, batched=True)\n",
    "test_tokenized = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_tokenized = train_tokenized.remove_columns([c for c in train_tokenized.column_names if c not in cols])\n",
    "test_tokenized = test_tokenized.remove_columns([c for c in test_tokenized.column_names if c not in cols])\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\")\n",
    "test_tokenized.set_format(type=\"torch\")\n",
    "\n",
    "print(f\"ËÆ≠ÁªÉÈõÜ: {len(train_tokenized)} Ê†∑Êú¨, ÊµãËØïÈõÜ: {len(test_tokenized)} Ê†∑Êú¨\")\n",
    "\n",
    "# ÂÆö‰πâÊ®°ÂûãÔºàÂ§öÊ†áÁ≠æ DistilBERTÔºâ\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "base_model_name = \"distilbert/distilbert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(base_model_name)\n",
    "config.num_labels = len(category_to_id)\n",
    "config.problem_type = \"multi_label_classification\"\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model initialized:\", model.__class__.__name__)\n",
    "print(\"Num labels:\", model.config.num_labels)\n",
    "print(\"Problem type:\", model.config.problem_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a93a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing checkpoint found, skip dummy save.\n"
     ]
    }
   ],
   "source": [
    "# ÂÆûÁé∞ checkpoint ‰øùÂ≠ò‰∏éÂä†ËΩΩÂ∑•ÂÖ∑ÂáΩÊï∞\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def save_checkpoint(state: Dict[str, Any], filename: Path):\n",
    "    \"\"\"‰øùÂ≠òËÆ≠ÁªÉÁä∂ÊÄÅÂà∞ÊåáÂÆöÊñá‰ª∂„ÄÇ\n",
    "\n",
    "    state Á§∫‰æã:\n",
    "    {\n",
    "        'epoch': int,\n",
    "        'global_step': int,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'best_metric': float\n",
    "    }\n",
    "    \"\"\"\n",
    "    filename = Path(filename)\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(state, filename)\n",
    "    print(f\"Checkpoint saved to {filename}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename: Path):\n",
    "    \"\"\"‰ªéÊåáÂÆöÊñá‰ª∂Âä†ËΩΩËÆ≠ÁªÉÁä∂ÊÄÅÔºåËøîÂõû (start_epoch, global_step, best_metric)„ÄÇ\"\"\"\n",
    "    filename = Path(filename)\n",
    "    if not filename.exists():\n",
    "        print(f\"No checkpoint found at {filename}, start from scratch.\")\n",
    "        return 0, 0, None\n",
    "\n",
    "    ckpt = torch.load(filename, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    if optimizer is not None and \"optimizer_state\" in ckpt:\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "    start_epoch = ckpt.get(\"epoch\", 0)\n",
    "    global_step = ckpt.get(\"global_step\", 0)\n",
    "    best_metric = ckpt.get(\"best_metric\", None)\n",
    "    print(f\"Loaded checkpoint from {filename}: epoch={start_epoch}, global_step={global_step}, best_metric={best_metric}\")\n",
    "    return start_epoch, global_step, best_metric\n",
    "\n",
    "\n",
    "# ÁÆÄÂçïÊµãËØïÔºö‰ªÖÂú®Á¨¨‰∏ÄÊ¨°ËøêË°åÊó∂‰øùÂ≠ò‰∏Ä‰∏™Á©∫ÁöÑ state Á§∫‰æã\n",
    "if not LAST_CKPT.exists():\n",
    "    dummy_state = {\n",
    "        \"epoch\": 0,\n",
    "        \"global_step\": 0,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"best_metric\": None,\n",
    "    }\n",
    "    save_checkpoint(dummy_state, LAST_CKPT)\n",
    "else:\n",
    "    print(\"Existing checkpoint found, skip dummy save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ccc2d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jylu/Projects/acafeed/.venv/lib/python3.14/site-packages/transformers/training_args.py:2301: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ü§ó Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from model/checkpoint_model1/model1_last.pt: epoch=0, global_step=0, best_metric=None\n",
      "Trainer initialized. start_epoch= 0 global_step= 0 best_metric= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/44/62vjt8dx0sd5w6cnwjv2k5gc0000gn/T/ipykernel_19304/816535516.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# ËÆ≠ÁªÉËÆæÁΩÆ‰∏é Trainer ÂàùÂßãÂåñÔºàÈõÜÊàê checkpoint ‰øùÂ≠ò‰∏éËá™Âä®Âä†ËΩΩÔºâ\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ÊåáÊ†áÈòàÂÄº\n",
    "def sigmoid_np(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "THRESH = 0.4  # Â§öÊ†áÁ≠æÈ¢ÑÊµãÈòàÂÄº\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = sigmoid_np(logits)\n",
    "    preds = (probs > THRESH).astype(int)\n",
    "\n",
    "    exact_match = (preds == labels).all(axis=1).mean()\n",
    "    f1_micro = f1_score(labels, preds, average=\"micro\", zero_division=0)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"exact_match\": exact_match,\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "    }\n",
    "\n",
    "\n",
    "output_dir = CHECKPOINT_DIR  # Áõ¥Êé•Â§çÁî® checkpoint ÁõÆÂΩï\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(output_dir),\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",  # Áî±Êàë‰ª¨Ëá™ÂÆö‰πâ save_checkpointÔºå‰∏ç‰ΩøÁî® HF ÂÜÖÂª∫‰øùÂ≠ò\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=False,\n",
    "    report_to=\"none\",\n",
    "    use_mps_device=(device.type == \"mps\"),\n",
    "    fp16=False,\n",
    "    dataloader_num_workers=0,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "# Ëá™Âä®Âä†ËΩΩÊúÄÊñ∞ checkpointÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ\n",
    "start_epoch, global_step, best_metric = load_checkpoint(model, optimizer, LAST_CKPT)\n",
    "if best_metric is None:\n",
    "    best_metric = 0.0\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized. start_epoch=\", start_epoch, \"global_step=\", global_step, \"best_metric=\", best_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d13f0d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training from epoch 0 / 3\n",
      "========================================\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jylu/Projects/acafeed/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='439' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 439/2346 03:49 < 16:41, 1.90 it/s, Epoch 0.56/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Trainer Ëá™Â∏¶ËÆ≠ÁªÉÂæ™ÁéØÔºå‰ΩÜÊàë‰ª¨Â∏åÊúõÂú® epoch Á≤íÂ∫¶‰∏ä‰øùÂ≠ò ckpt\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m global_step = train_result.global_step\n\u001b[32m     17\u001b[39m eval_metrics = trainer.evaluate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/acafeed/.venv/lib/python3.14/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/acafeed/.venv/lib/python3.14/site-packages/transformers/trainer.py:2679\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2674\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2683\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ‰∏ªËÆ≠ÁªÉÂæ™ÁéØÔºöÊîØÊåÅÈáçÂ§çËøêË°åÊó∂Ëá™Âä®‰ªé checkpoint ÊÅ¢Â§ç\n",
    "\n",
    "num_epochs = training_args.num_train_epochs\n",
    "\n",
    "print(f\"Start training from epoch {start_epoch} / {num_epochs}\")\n",
    "\n",
    "best_metric_local = best_metric\n",
    "\n",
    "for epoch in range(int(start_epoch), int(num_epochs)):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Trainer Ëá™Â∏¶ËÆ≠ÁªÉÂæ™ÁéØÔºå‰ΩÜÊàë‰ª¨Â∏åÊúõÂú® epoch Á≤íÂ∫¶‰∏ä‰øùÂ≠ò ckpt\n",
    "    train_result = trainer.train()\n",
    "    global_step = train_result.global_step\n",
    "\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    print(\"Eval metrics:\", eval_metrics)\n",
    "\n",
    "    # ‰øùÂ≠òÊúÄÊñ∞ checkpoint\n",
    "    state = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"global_step\": int(global_step),\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"best_metric\": float(best_metric_local),\n",
    "    }\n",
    "    save_checkpoint(state, LAST_CKPT)\n",
    "\n",
    "    # Ê†πÊçÆ f1_micro Êõ¥Êñ∞ best checkpoint\n",
    "    current_metric = eval_metrics.get(\"f1_micro\", 0.0)\n",
    "    if current_metric > best_metric_local:\n",
    "        best_metric_local = current_metric\n",
    "        state[\"best_metric\"] = float(best_metric_local)\n",
    "        save_checkpoint(state, BEST_CKPT)\n",
    "        print(f\"New best f1_micro={best_metric_local:.4f}, saved to BEST_CKPT\")\n",
    "\n",
    "print(\"Training finished. Best f1_micro=\", best_metric_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea125e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êé®ÁêÜ‰∏éÂ§öÊ†áÁ≠æÈ¢ÑÊµãÁ§∫‰æãÔºà‰ΩøÁî® best Êàñ last checkpointÔºâ\n",
    "\n",
    "# ‰ºòÂÖàÂä†ËΩΩÊúÄ‰Ω≥ checkpoint\n",
    "if BEST_CKPT.exists():\n",
    "    load_checkpoint(model, optimizer=None, filename=BEST_CKPT)\n",
    "else:\n",
    "    load_checkpoint(model, optimizer=None, filename=LAST_CKPT)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "sample_titles = [\n",
    "    filtered_df.iloc[0][\"Title\"],\n",
    "    filtered_df.iloc[10][\"Title\"],\n",
    "    filtered_df.iloc[100][\"Title\"],\n",
    "]\n",
    "\n",
    "encoded = tokenizer(sample_titles, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "if \"token_type_ids\" in encoded:\n",
    "    encoded.pop(\"token_type_ids\")\n",
    "\n",
    "encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded)\n",
    "    probs = torch.sigmoid(outputs.logits).cpu()\n",
    "\n",
    "for title, prob in zip(sample_titles, probs):\n",
    "    pred_indices = (prob > THRESH).nonzero(as_tuple=True)[0].tolist()\n",
    "    pred_labels = [(id2label[i], float(prob[i])) for i in pred_indices]\n",
    "    top5 = sorted([(id2label[i], float(p)) for i, p in enumerate(prob)], key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Title:\", title[:100])\n",
    "    print(f\"È¢ÑÊµãÊ†áÁ≠æ (>{THRESH}): {len(pred_labels)} ‰∏™\")\n",
    "    for label, score in pred_labels:\n",
    "        print(f\"  - {label}: {score:.3f}\")\n",
    "    print(\"\\nTop 5 Ê†áÁ≠æ:\")\n",
    "    for label, score in top5:\n",
    "        print(f\"  - {label}: {score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acafeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
