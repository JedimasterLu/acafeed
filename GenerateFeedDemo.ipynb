{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2571ee8",
   "metadata": {},
   "source": [
    "# 方案A Demo：本地生成 feed.xml 并用 raw 链接给 foLo 订阅\n",
    "\n",
    "- 本 Notebook 演示如何聚合 RSS、筛选并在仓库根目录生成 `feed.xml`。\n",
    "- 推送到远端后，可用如下 raw 链接在 foLo/Feedly 订阅：\n",
    "\n",
    "``\n",
    "https://raw.githubusercontent.com/JedimasterLu/acafeed/feedemit/feed.xml\n",
    "``\n",
    "\n",
    "你也可以把分支名改为你的默认分支（例如 main）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd9ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from feedgen.feed import FeedGenerator\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import re, os\n",
    "from typing import Any, Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102a89a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output -> /Users/jylu/Projects/acafeed/feed.xml\n"
     ]
    }
   ],
   "source": [
    "# 配置：源、过滤规则、元信息与输出位置\n",
    "\n",
    "SOURCES = [\n",
    "    {\"name\": \"Nature Materials\", \"url\": \"http://www.nature.com/nmat/current_issue/rss/\"},\n",
    "    # 在这里添加更多源...\n",
    "]\n",
    "\n",
    "FILTERS = {\n",
    "    \"include\": [],   # [\"ai\", \"ml\"] 仅包含包含任意关键词的条目\n",
    "    \"exclude\": [],   # [\"ad\", \"sponsor\"] 排除包含任意关键词的条目\n",
    "    \"since_days\": 7, # 仅保留最近 N 天；设为 None/删除以关闭\n",
    "    \"max_entries\": 100, # 输出条目上限\n",
    "}\n",
    "\n",
    "META = {\n",
    "    \"title\": \"AcaFeed Combined Feed\",\n",
    "    \"description\": \"Aggregated feed generated locally\",\n",
    "    \"home_page\": \"https://github.com/JedimasterLu/acafeed\",\n",
    "    # 可选：如果已确定最终订阅URL，可填入作为 rel=self\n",
    "    # \"feed_link\": \"https://raw.githubusercontent.com/JedimasterLu/acafeed/feedemit/feed.xml\"\n",
    "}\n",
    "\n",
    "OUTPUT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"feed.xml\"))\n",
    "print(\"Output ->\", OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761c50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具函数：标准化文本 / 解析时间 / 去重键\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def normalize_text(s: Optional[str]) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)\n",
    "    return s.strip().lower()\n",
    "\n",
    "\n",
    "def parse_dt(entry: Dict[str, Any]) -> datetime:\n",
    "    for field in (\"published_parsed\", \"updated_parsed\"):\n",
    "        dt_struct = entry.get(field)\n",
    "        if dt_struct is not None:\n",
    "            try:\n",
    "                return datetime(*dt_struct[:6], tzinfo=timezone.utc)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "\n",
    "def entry_key(entry: Dict[str, Any]) -> str:\n",
    "    return entry.get(\"link\") or entry.get(\"id\") or normalize_text(entry.get(\"title\") or \"\")\n",
    "\n",
    "\n",
    "def fetch_entries(sources: List[Dict[str, str]]) -> List[Dict[str, Any]]:\n",
    "    all_entries = []\n",
    "    for src in sources:\n",
    "        url = src.get(\"url\") or src.get(\"link\")\n",
    "        if not url:\n",
    "            continue\n",
    "        parsed = feedparser.parse(url)\n",
    "        for e in getattr(parsed, \"entries\", []) or []:\n",
    "            e[\"_source_name\"] = src.get(\"name\") or url\n",
    "            all_entries.append(e)\n",
    "    return all_entries\n",
    "\n",
    "\n",
    "def apply_filters(entries: List[Dict[str, Any]], filters: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    include = [x.lower() for x in (filters.get(\"include\") or []) if x]\n",
    "    exclude = [x.lower() for x in (filters.get(\"exclude\") or []) if x]\n",
    "    since_days = filters.get(\"since_days\")\n",
    "    cutoff = None\n",
    "    if isinstance(since_days, int) and since_days > 0:\n",
    "        cutoff = datetime.now(timezone.utc) - timedelta(days=since_days)\n",
    "\n",
    "    def ok(e: Dict[str, Any]) -> bool:\n",
    "        text = \" \".join([normalize_text(e.get(\"title\")), normalize_text(e.get(\"summary\")), normalize_text(e.get(\"description\"))])\n",
    "        if include and not any(k in text for k in include):\n",
    "            return False\n",
    "        if exclude and any(k in text for k in exclude):\n",
    "            return False\n",
    "        if cutoff is not None and parse_dt(e) < cutoff:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    return [e for e in entries if ok(e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7b1f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /Users/jylu/Projects/acafeed/feed.xml with 6 entries\n"
     ]
    }
   ],
   "source": [
    "# 生成 feed.xml\n",
    "\n",
    "# 1) 拉取与筛选\n",
    "entries = fetch_entries(SOURCES)\n",
    "filtered = apply_filters(entries, FILTERS)\n",
    "\n",
    "# 2) 去重与排序\n",
    "seen = set()\n",
    "unique = []\n",
    "for e in filtered:\n",
    "    k = entry_key(e)\n",
    "    if not k or k in seen:\n",
    "        continue\n",
    "    seen.add(k)\n",
    "    unique.append(e)\n",
    "unique.sort(key=parse_dt, reverse=True)\n",
    "\n",
    "# 3) 裁剪数量\n",
    "max_entries = FILTERS.get(\"max_entries\")\n",
    "if isinstance(max_entries, int) and max_entries > 0:\n",
    "    unique = unique[:max_entries]\n",
    "\n",
    "# 4) 构建 RSS 并写入\n",
    "fg = FeedGenerator()\n",
    "fg.id(META.get(\"home_page\") or \"https://github.com/JedimasterLu/acafeed\")\n",
    "fg.title(META.get(\"title\") or \"AcaFeed\")\n",
    "fg.link(href=META.get(\"home_page\") or \"https://github.com/JedimasterLu/acafeed\", rel=\"alternate\")\n",
    "if META.get(\"feed_link\"):\n",
    "    fg.link(href=META[\"feed_link\"], rel=\"self\")\n",
    "fg.description(META.get(\"description\") or META.get(\"title\") or \"AcaFeed\")\n",
    "fg.language(\"en\")\n",
    "\n",
    "for e in unique:\n",
    "    fe = fg.add_entry()\n",
    "    fe.id(entry_key(e))\n",
    "    fe.title(e.get(\"title\") or (normalize_text(e.get(\"summary\"))[:140] or \"Untitled\"))\n",
    "    if e.get(\"link\"):\n",
    "        fe.link(href=e[\"link\"])\n",
    "    if e.get(\"summary\") or e.get(\"description\"):\n",
    "        fe.description(e.get(\"summary\") or e.get(\"description\"))\n",
    "    fe.published(parse_dt(e))\n",
    "    if e.get(\"_source_name\"):\n",
    "        fe.category(term=e.get(\"_source_name\"))\n",
    "\n",
    "fg.rss_file(OUTPUT_PATH, pretty=True)\n",
    "print(f\"Wrote {OUTPUT_PATH} with {len(unique)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca4f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='UTF-8'?>\n",
      "<rss xmlns:atom=\"http://www.w3.org/2005/Atom\" xmlns:content=\"http://purl.org/rss/1.0/modules/content/\" version=\"2.0\">\n",
      "  <channel>\n",
      "    <title>AcaFeed Combined Feed</title>\n",
      "    <link>https://github.com/JedimasterLu/acafeed</link>\n",
      "    <description>Aggregated feed generated locally</description>\n",
      "    <docs>http://www.rssboard.org/rss-specification</docs>\n",
      "    <generator>python-feedgen</generator>\n",
      "    <language>en</language>\n",
      "    <lastBuildDate>Tue, 11 Nov 2025 21:25:48 +0000</lastBuildDate>\n",
      "    <item>\n",
      "      <title>Mechano-induced patterned domain formation by monocytes</title>\n",
      "      <link>https://www.nature.com/articles/s41563-025-02397-2</link>\n",
      "      <description>&lt;p&gt;Nature Materials, Published online: 05 November 2025; &lt;a href=\"https://www.nature.com/articles/s41563-025-02397-2\"&gt;doi:10.1038/s41563-025-02397-2&lt;/a&gt;&lt;/p&gt;Human primary monocytes reversibly phase separate into regular, multicellular, multilayered domains on soft matrices with physiological stiffness due to local activation and global inhibition processes that occur during random cell migration.</description>\n",
      "      <guid isPermaLink=\"false\">https://www.nature.com/articles/s41563-025-02397-2</guid>\n",
      "      <category>Nature Materials</category>\n",
      "      <pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate>\n",
      "    </item>\n",
      "    <item>\n",
      "      <title>Diffracting atoms in solids</title>\n",
      "      <link>https://www.nature.com/articles/s41563-025-02401-9</link>\n",
      "      <description>&lt;p&gt;Nature Materials, Published online: 05 November 2025; &lt;a href=\"https://www.nature.com/articles/s41563-025-02401-9\"&gt;doi:10.1038/s41563-025-02401-9&lt;/a&gt;&lt;/p&gt;Diffracting atoms in solids</description>\n",
      "      <guid isPermaLink=\"false\">https://www.nature.com/articles/s41563-025-02401-9</guid>\n",
      "      <category>Nature Materials</category>\n",
      "      <pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate>\n",
      "    </item>\n",
      "    <item>\n",
      "      <title>Non-invasive bioinert room-temperature quantum sensor from silicon carbide qubits</title>\n",
      "      <link>https://www.nature.com/articles/s41563-025-02382-9</link>\n",
      "      <description>&lt;p&gt;Nature Materials, Published online: 06 November 2025; &lt;a href=\"https://www.nature.com/articles/s41563-025-02382-9\"&gt;doi:10.1038/s41563-025-02382-9&lt;/a&gt;&lt;/p&gt;Alkene-terminated silicon carbide surfaces are proposed as a room-temperature divacancy spin qubit quantum sensor suitable for bioimaging and nanoscale nuclear spin sensing.</description>\n",
      "      <guid isPermaLink=\"false\">https://www.nature.com/articles/s41563-025-02382-9</guid>\n",
      "      <category>Nature Materials</category>\n",
      "      <pubDate>Thu, 06 Nov 2025 00:00:00 +0000</pubDate>\n",
      "    </item>\n",
      "    <item>\n",
      "      <title>Mechanical non-reciprocity programmed by shear jamming in soft composite solids</title>\n",
      "      <link>https://www.nature.com/articles/s41563-025-02407-3</link>\n",
      "      <description>&lt;p&gt;Nature Materials, Published online: 07 November 2025; &lt;a href=\"https://www.nature.com/articles/s41563-025-02407-3\"&gt;doi:10.1038/s41563-025-02407-3&lt;/a&gt;&lt;/p&gt;Using the shear jamming transition within soft composite solids, non-reciprocal mechanics are achieved for the asymmetric spatiotemporal control of soft materials.</description>\n",
      "      <guid isPermaLink=\"false\">https://www.nature.com/articles/s41563-025-02407-3</guid>\n",
      "      <category>Nature Materials</category>\n",
      "      <pubDate>Fri, 07 Nov 2025 00:00:00 +0000</pubDate>\n",
      "    </item>\n"
     ]
    }
   ],
   "source": [
    "# 查看 feed.xml 前若干行\n",
    "\n",
    "with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.rstrip())\n",
    "        if i > 40:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587c4c8",
   "metadata": {},
   "source": [
    "## 推送与订阅\n",
    "\n",
    "1. 在终端提交并推送：\n",
    "\n",
    "```fish\n",
    "git add feed.xml\n",
    "git commit -m \"chore: update feed.xml\"\n",
    "git push origin feedemit\n",
    "```\n",
    "\n",
    "2. 在 foLo 的新增订阅里，粘贴这个 URL（当前分支 `feedemit`）：\n",
    "\n",
    "``\n",
    "https://raw.githubusercontent.com/JedimasterLu/acafeed/feedemit/feed.xml\n",
    "```\n",
    "\n",
    "若你用的是其他默认分支（如 `main`），把 URL 中的分支名替换为 `main` 即可。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acafeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
